# Translation Pipeline â€“ LangGraph Ã— LangChain

This project is a **minimal yet production-grade** example of how to combine [LangGraph](https://github.com/langchain-ai/langgraph) with [LangChain](https://github.com/langchain-ai/langchain) to build a translation workflow that enforces both a *style guide* and a *domain-specific glossary*.

The pipeline is intentionally small (two nodes) so the focus stays on the architecture and testing discipline rather than on lavish prompt engineering.

---
## Workflow Overview

```
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  glossary_filter  â”‚â”€â”€â–¶â”€â”€â–¶â”€â”€â”‚    translator     â”‚â”€â”€â–¶â”€â”€â–¶â”€â”€ END
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           (RapidFuzz)                  (OpenAI LLM)
```

1. **Glossary Filter** â€“ Scans the source text and keeps **only** the glossary terms that actually appear (RapidFuzz fuzzy-matching, score â‰¥ 75).
2. **Translator** â€“ Crafts a prompt embedding the style guide & the filtered glossary, then calls `gpt-4o` (or a mocked model during tests) to obtain the translated content.

Both nodes return *partial* state updates which LangGraph merges into the global `TranslationState` object, keeping the nodes completely decoupled.

---
## Repository Layout

```
translation/
â”œâ”€â”€ data/                 # Example input, glossary and style guide
â”‚   â”œâ”€â”€ glossary.csv
â”‚   â”œâ”€â”€ input.txt
â”‚   â””â”€â”€ style_guide.md
â”œâ”€â”€ nodes/                # Individual LangGraph nodes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ filter_glossary.py
â”‚   â””â”€â”€ translate_content.py
â”œâ”€â”€ tests/                # pytest unit tests with extensive mocking
â”‚   â”œâ”€â”€ test_filter_glossary.py
â”‚   â””â”€â”€ test_translate_content.py
â”œâ”€â”€ graph.py              # Graph wiring â€“ defines the node topology
â”œâ”€â”€ main.py               # Example CLI entry-point that runs the full graph
â”œâ”€â”€ state.py              # TypedDict shared state definition
â”œâ”€â”€ pyproject.toml        # Poetry-compatible metadata + dependencies
â”œâ”€â”€ uv.lock               # Machine-generated lock-file (UV)
â””â”€â”€ README.md             # You are here âœ”
```

---
## Getting Started

### 1. Clone & create a virtual environment

```bash
# Install UV if you don't have it yet
pip install uv

# Inside the repo...
uv venv             # create .venv using uv
uv pip install -r pyproject.toml  # sync dependencies from pyproject
```

> **Why UV?** UV is a fast, modern Python packaging tool promoted for this project. Standard `pip` or `poetry` will work too, but the lock-file is optimised for UV.

### 2. Provide your OpenAI credentials

Create a `.env` file at the project root:

```ini
OPENAI_API_KEY=sk-...
```

The code automatically loads `.env` via `python-dotenv` on startup.

### 3. Run the example

```bash
python -m translation.main  # prints original & translated content
```

#### Command-line options:

```bash
# Specify target language (default: English)
python -m translation.main --language Spanish
python -m translation.main -l French

# Specify input file (default: data/input.txt)
python -m translation.main --input data/custom_input.txt
python -m translation.main -i data/another_file.txt

# Combine options
python -m translation.main --language German --input data/technical_doc.txt
```

A Mermaid diagram of the graph will be written to `graph-visualization.md`.

### 4. Run the test-suite

```bash
pytest -q
```

The tests use a **dummy** LLM implementation so they are 100 % offline / free.

---
## Extending the Pipeline

* **Add quality-assurance nodes** â€“ e.g. back-translation consistency check.
* **Persist history** â€“ swap the in-memory `messages` list for a vector store.
* **Alternative models** â€“ patch `ChatOpenAI` with Anthropic/LLM of choice; the fallback logic in `translate_content.py` keeps tests untouched.

PRs welcome ðŸŽ‰
